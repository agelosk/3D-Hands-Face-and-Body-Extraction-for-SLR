{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, keras, os, tensorflow as tf, scipy.misc\n",
    "from PIL import Image\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional, BatchNormalization, ZeroPadding2D\n",
    "from keras.layers import TimeDistributed, Conv2D, MaxPooling2D, Dense, Dropout, Flatten, Activation, LeakyReLU, Input\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = np.load('data/x_train_op.npy',allow_pickle=True), np.load('data/y_train_op.npy')\n",
    "x_val,   y_val   = np.load('data/x_dev_op.npy',allow_pickle=True),   np.load('data/y_dev_op.npy')\n",
    "x_test,  y_test  = np.load('data/x_test_op.npy',allow_pickle=True),  np.load('data/y_test_op.npy')\n",
    "\n",
    "CLASSES = max(y_train) + 1\n",
    "name    = 'models/desired_name.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence) :\n",
    "  \n",
    "    def __init__(self, images, labels, batch_size) :\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    \n",
    "    def __len__(self) :\n",
    "        return (np.ceil(len(self.images) / float(self.batch_size))).astype(np.int)\n",
    "  \n",
    "  \n",
    "    def __getitem__(self, idx) :\n",
    "        \n",
    "        batch_x = self.images[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "        batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "        \n",
    "        return np.expand_dims(np.array(batch_x[0]),0),  np.expand_dims(np.squeeze([to_categorical(batch_y,CLASSES)]*len(batch_x[0])),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_model(INPUT_SIZE):\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64,kernel_size=(3,3),padding='same',strides=1,input_shape = INPUT_SIZE))\n",
    "    model.add(Conv2D(64,kernel_size=(3,3),padding='same',strides=1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(128,kernel_size=(3,3),padding='same',strides=1))\n",
    "    model.add(Conv2D(128,kernel_size=(3,3),padding='same',strides=1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(256,kernel_size=(3,3),padding='same',strides=1))\n",
    "    model.add(Conv2D(256,kernel_size=(3,3),padding='same',strides=1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(640,kernel_size=(3,3),padding='same',strides=1))\n",
    "    model.add(Conv2D(640,kernel_size=(3,3),padding='same',strides=1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(alpha=0.3))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def lstm_model(INPUT_SIZE,classes):\n",
    "    \n",
    "    model = Sequential()\n",
    "    #conv = conv_model(INPUT_SIZE)\n",
    "    shape = (None,) + (INPUT_SIZE)\n",
    "\n",
    "    model.add(Bidirectional(LSTM(256,return_sequences=True), input_shape=shape))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(TimeDistributed(Dense(classes,activation='softmax')))\n",
    "    \n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOS: Works only for batch_size = 1 !\n",
    "train_generator    = DataGenerator(images=x_train, labels=y_train, batch_size=1)\n",
    "val_generator      = DataGenerator(images=x_val,   labels=y_val,   batch_size=1)\n",
    "test_generator     = DataGenerator(images=x_test,  labels=y_test,  batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "\n",
    "config = tf.ConfigProto( device_count = {'GPU': 0})\n",
    "config.gpu_options.allow_growth = True \n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = lstm_model((201,),CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "class TestCallback(Callback):\n",
    "    def __init__(self, test_data):\n",
    "        self.test_data = test_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        loss, acc = self.model.evaluate_generator(test_generator)\n",
    "        print('\\nTesting loss: {}, acc: {}\\n'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='min',restore_best_weights=True)\n",
    "mcp_save = ModelCheckpoint(name, save_best_only=True, monitor='val_loss', mode='min')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, epsilon=1e-4, mode='min')\n",
    "    \n",
    "model.compile(loss='categorical_crossentropy',optimizer=keras.optimizers.SGD(),metrics=['accuracy'])\n",
    "model.fit_generator(generator=train_generator,epochs=200,validation_data = val_generator,\n",
    "                    verbose = 1,callbacks=[earlystop,mcp_save,reduce_lr_loss,TestCallback(test_generator)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(name)\n",
    "model.evaluate_generator(test_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
